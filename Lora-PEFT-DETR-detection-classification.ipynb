{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNoZsJ5C/yaCx/c087/KI2E"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"C82sCL96z_4k"}},{"cell_type":"markdown","source":["## Installations"],"metadata":{"id":"2XokjriqwUPE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Q4FvXe1wAWj"},"outputs":[],"source":["# pip install transformers datasets peft bitsandbytes accelerate torchvision\n","!pip install bitsandbytes"]},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"QwkbQvkXwWbt"}},{"cell_type":"code","source":["import torch\n","from transformers import DetrImageProcessor, DetrForObjectDetection, TrainingArguments, Trainer\n","from peft import get_peft_model, LoraConfig, prepare_model_for_kbit_training, TaskType\n","from datasets import load_dataset, Features, Sequence, Value, Array2D, Array3D\n","import bitsandbytes as bnb"],"metadata":{"id":"zAOEasj6wSKc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Id <-> label look-up maps"],"metadata":{"id":"fawbBUskwZN0"}},{"cell_type":"code","source":["id2label = {\n","    0: \"Auto\", 1: \"2-Wheeler\", 2: \"Bicycle\", 3: \"Bus\", 4: \"Hatchback\",\n","    5: \"LCV\", 6: \"Mini-bus\", 7: \"MUV\", 8: \"Sedan\", 9: \"SUV\",\n","    10: \"Tempo-traveller\", 11: \"Truck\", 12: \"Van\", 13: \"Vehicle (others)\"\n","}\n","label2id = {v: k for k, v in id2label.items()}"],"metadata":{"id":"jVEp0tq1wc38"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GLDyR0-d14Fc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load processor and model (4-bit quantized)"],"metadata":{"id":"RTc-uZnowevr"}},{"cell_type":"code","source":["processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n","\n","model = DetrForObjectDetection.from_pretrained(\n","    \"facebook/detr-resnet-50\",\n","    num_labels=len(id2label),\n","    ignore_mismatched_sizes=True,\n","    id2label=id2label,\n","    label2id=label2id,\n","    device_map=\"auto\",\n","    load_in_4bit=True,\n","    quantization_config=bnb.nn.Linear4bitLt.QuantizationConfig(\n","        load_in_4bit=True,\n","        bnb_4bit_compute_dtype=torch.float16,\n","        bnb_4bit_use_double_quant=True,\n","        bnb_4bit_quant_type=\"nf4\"\n","    )\n",")"],"metadata":{"id":"EjoQwhJFwoMM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Configure LoRA"],"metadata":{"id":"_2iGtxAZwpEN"}},{"cell_type":"code","source":["model = prepare_model_for_kbit_training(model)\n","\n","peft_config = LoraConfig(\n","    r=8,\n","    lora_alpha=16,\n","    lora_dropout=0.1,\n","    bias=\"none\",\n","    task_type=TaskType.OBJECT_DETECTION,\n","    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"ffn\"]  # adjust based on DETR layer names\n",")\n","\n","model = get_peft_model(model, peft_config)\n","model.print_trainable_parameters()"],"metadata":{"id":"I-YjsMz-wy_L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load dataset"],"metadata":{"id":"okNWhhrKw04r"}},{"cell_type":"code","source":["dataset = load_dataset(\n","    \"ybelkada/coco-2017\",  # sample COCO-style dataset (replace with yours)\n","    split={\"train\": \"train[:100]\", \"val\": \"validation[:50]\"}  # for example/testing\n",")"],"metadata":{"id":"LFW8xVh9w33z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Preprocessing"],"metadata":{"id":"tnty1D1pw7pM"}},{"cell_type":"code","source":["def preprocess(example):\n","    image = example['image']\n","    annotations = {\n","        \"image_id\": example[\"image_id\"],\n","        \"annotations\": example[\"objects\"]\n","    }\n","    encoding = processor(images=image, annotations=annotations, return_tensors=\"pt\")\n","    encoding = {k: v.squeeze() for k, v in encoding.items()}\n","    return encoding\n","\n","train_dataset = dataset[\"train\"].map(preprocess, remove_columns=dataset[\"train\"].column_names)\n","val_dataset = dataset[\"val\"].map(preprocess, remove_columns=dataset[\"val\"].column_names)"],"metadata":{"id":"A0lF6_bPw7K0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training parameters"],"metadata":{"id":"SA4UxiQ-xBXD"}},{"cell_type":"code","source":["args = TrainingArguments(\n","    output_dir=\"./detr-resnet-50-vehicle-lora\",\n","    per_device_train_batch_size=4,\n","    per_device_eval_batch_size=2,\n","    num_train_epochs=10,\n","    learning_rate=2e-5,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    logging_steps=10,\n","    fp16=True,\n","    push_to_hub=False,\n","    report_to=\"none\"\n",")"],"metadata":{"id":"cLQaErYIxIkj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training loop configuration"],"metadata":{"id":"8w0wChf9xK77"}},{"cell_type":"code","source":["trainer = Trainer(\n","    model=model,\n","    args=args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    tokenizer=processor,\n",")"],"metadata":{"id":"8cyGBu2MwL38"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"id":"SVRsXdShxP5V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Push to Huggingface"],"metadata":{"id":"bnFnLbj40_kN"}},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","notebook_login()"],"metadata":{"id":"oRVQ2yJy1FYt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.push_to_hub(\"Facebook's detection transformer architecture with resnet 50 supervised finetuned for detection and classification of vehicles\")"],"metadata":{"id":"4NgRCWpT1G2N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Inference"],"metadata":{"id":"f74vAq5rzthD"}},{"cell_type":"markdown","source":["## Load base model with lora weights"],"metadata":{"id":"lvSNf83MzwZs"}},{"cell_type":"code","source":["from transformers import DetrImageProcessor, DetrForObjectDetection\n","from peft import PeftModel\n","import torch\n","import requests\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","\n","base_model_name = \"facebook/detr-resnet-50\"\n","model_name = \"your-username/detr-resnet-50-vehicle-lora\"\n","\n","# Load base model\n","base_model = DetrForObjectDetection.from_pretrained(\n","    base_model_name,\n","    num_labels=len(id2label),\n","    ignore_mismatched_sizes=True,\n","    id2label=id2label,\n","    label2id=label2id\n","    device_map=\"auto\",\n","    load_in_4bit=True\n",")\n","\n","# Apply PEFT weights\n","model = PeftModel.from_pretrained(base_model, model_name)\n","model.eval()\n","\n","# Load processor\n","processor = DetrImageProcessor.from_pretrained(base_model_name)"],"metadata":{"id":"D99LJWFHzy-t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load the image to be inferenced"],"metadata":{"id":"02WUwUn9z1ae"}},{"cell_type":"code","source":["# Load an image\n","url = \"https://c8.alamy.com/comp/2BFNHGX/group-of-cute-cats-on-white-background-2BFNHGX.jpg\"\n","image = Image.open(requests.get(url, stream=True).raw)\n","\n","# Preprocess\n","inputs = processor(images=image, return_tensors=\"pt\")\n","\n","# Inference\n","with torch.no_grad():\n","    outputs = model(**inputs)\n","\n","# Get logits and boxes\n","logits = outputs.logits\n","boxes = outputs.pred_boxes\n","\n","# Apply softmax to get class probabilities\n","probs = logits.softmax(-1)[0, :, :-1]  # Remove \"no-object\" class\n","scores, labels = probs.max(-1)\n","\n","# Thresholding detections\n","threshold = 0.9\n","keep = scores > threshold"],"metadata":{"id":"8NVbGDyUz3id"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Visualization"],"metadata":{"id":"vA7vJlC7z5Ec"}},{"cell_type":"code","source":["plt.figure(figsize=(10, 8))\n","plt.imshow(image)\n","ax = plt.gca()\n","\n","for score, label, box in zip(scores[keep], labels[keep], boxes[0][keep]):\n","    box = box.cpu() * torch.tensor([image.width, image.height, image.width, image.height])\n","    x_center, y_center, width, height = box\n","    x = x_center - width / 2\n","    y = y_center - height / 2\n","\n","    rect = patches.Rectangle((x, y), width, height, linewidth=2, edgecolor='red', facecolor='none')\n","    ax.add_patch(rect)\n","    label_name = model.config.id2label[label.item()]\n","    ax.text(x, y, f\"{label_name}: {score:.2f}\", bbox=dict(facecolor='yellow', alpha=0.5))\n","\n","plt.axis('off')\n","plt.title(\"DETR Object Detection\")\n","plt.show()"],"metadata":{"id":"6oqOOeYoz7Nk"},"execution_count":null,"outputs":[]}]}