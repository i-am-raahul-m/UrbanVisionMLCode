{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPVMQ3kD0QAWJKbsF6OU/71"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Installations"],"metadata":{"id":"Gc79O7B_pL6q"}},{"cell_type":"code","source":["# pip install torch torchvision matplotlib tqdm"],"metadata":{"id":"5WDK_3jYpJ50"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"TWrJolanpQQy"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as T\n","from torchvision.models.detection import fasterrcnn_resnet50_fpn\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from tqdm import tqdm"],"metadata":{"id":"wdWX6ya2oUpi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Define Dataset and Collate Function"],"metadata":{"id":"KpBhLYs1oW-B"}},{"cell_type":"code","source":["transform = T.Compose([\n","    T.ToTensor(),\n","])\n","\n","dataset = VehicleDataset(image_dir=\"images\", label_dir=\"labels\", transform=transform)\n","\n","def collate_fn(batch):\n","    images, targets = zip(*batch)\n","    return list(images), list(targets)\n","\n","dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn, num_workers=4, pin_memory=True)"],"metadata":{"id":"Fnlfni6gocMa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Load Faster R-CNN and Modify for Custom Classes"],"metadata":{"id":"qC2K-EjwoeXr"}},{"cell_type":"code","source":["num_classes = 1 + len(set([lbl for img, tgt in dataset for lbl in tgt[\"labels\"]]))  # 1 background + N classes\n","\n","model = fasterrcnn_resnet50_fpn(pretrained=True)\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)"],"metadata":{"id":"8PUSTS7Loh9a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. Optimizer & Training Loop"],"metadata":{"id":"n-gjYsr8okbh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IB3RtqCqnvb5"},"outputs":[],"source":["params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.Adam(params, lr=1e-4)\n","\n","num_epochs = 10\n","model.train()\n","\n","for epoch in range(num_epochs):\n","    total_loss = 0.0\n","    progress = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n","\n","    for images, targets in progress:\n","        images = [img.to(device) for img in images]\n","        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","        loss_dict = model(images, targets)\n","        loss = sum(loss for loss in loss_dict.values())\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","        progress.set_postfix(loss=loss.item())\n","\n","    print(f\"Epoch {epoch+1}: Average Loss = {total_loss / len(dataloader):.4f}\")"]},{"cell_type":"markdown","source":["## Inference"],"metadata":{"id":"c_7inaKRo6Gj"}},{"cell_type":"code","source":["model.eval()\n","image = dataset[0][0].to(device)\n","with torch.no_grad():\n","    predictions = model([image])\n","    # output: boxes, labels, scores"],"metadata":{"id":"5K64lyHvo5Xh"},"execution_count":null,"outputs":[]}]}